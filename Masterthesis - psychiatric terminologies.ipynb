{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "#NEUROTIC DESCRIPTIVES\n",
    "\n",
    "#descriptives of neurotic metadata (retweets, replies, likes, quote count and offensive data)\n",
    "dfneurotic = pd.read_csv('2neurotic_offensive_analysis.csv', low_memory=False)\n",
    "dfneurotic_descr_tweet = dfneurotic[['retweetCount', 'replyCount', 'likeCount', 'quoteCount', 'predominant_label', 'offensive', 'not_offensive']]\n",
    "\n",
    "# Create a table with specific descriptive statistics\n",
    "descriptive_stats_neurotic = dfneurotic_descr_tweet.describe().loc[['count', 'mean', 'std', 'min', 'max']]\n",
    "\n",
    "# Display the table\n",
    "print(\"Descriptive Statistics Table for Neurotic:\")\n",
    "print(descriptive_stats_neurotic)\n",
    "\n",
    "\n",
    "# Set up the matplotlib figure for density graphs\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create box plots for numeric columns only\n",
    "dfneurotic_descr_tweet.boxplot(column=['retweetCount', 'replyCount', 'likeCount', 'quoteCount'])\n",
    "\n",
    "# Label the axes and add a title for the box plot\n",
    "plt.xlabel('Interaction Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Box Plot of Neurotic Metadata')\n",
    "\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('Neurotic_Metadata_Box_Plot.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "#NEUROTICISM DESCRIPTIVES\n",
    "\n",
    "#descriptives of neuroticism metadata (retweets, replies, likes, quote count and offensive data)\n",
    "dfneuroticism = pd.read_csv('2neuroticism_offensive_analysis.csv', low_memory=False)\n",
    "dfneuroticism_descr_tweet = dfneuroticism[['retweetCount', 'replyCount', 'likeCount', 'quoteCount', 'predominant_label', 'offensive', 'not_offensive']]\n",
    "\n",
    "# Create a table with specific descriptive statistics\n",
    "descriptive_stats_neuroticism = dfneuroticism_descr_tweet.describe().loc[['count', 'mean', 'std', 'min', 'max']]\n",
    "\n",
    "# Display the table\n",
    "print(\"Descriptive Statistics Table for Neuroticism:\")\n",
    "print(descriptive_stats_neuroticism)\n",
    "\n",
    "\n",
    "# Set up the matplotlib figure for density graphs\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create box plots for numeric columns only\n",
    "dfneuroticism_descr_tweet.boxplot(column=['retweetCount', 'replyCount', 'likeCount', 'quoteCount'])\n",
    "\n",
    "# Label the axes and add a title for the box plot\n",
    "plt.xlabel('Interaction Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Box Plot of Neuroticism Metadata')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('Neuroticism_Metadata_Box_Plot.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "#TWEET FREQUENCY GRAPH\n",
    "\n",
    "#load dataset for visualisation + parse dates - essential first step\n",
    "tweet_df1 = pd.read_csv('dat_neurotic_short.csv', \\\n",
    "    parse_dates=['date', 'acc_created'])\n",
    "\n",
    "tweet_df2 = pd.read_csv('dat_neuroticism_short.csv', \\\n",
    "    parse_dates=['date', 'acc_created'])\n",
    "#visualisation of Pro-anorexia and pro-recovery tweet frequency per 30 days\n",
    "tweet_df_pa = tweet_df1.groupby(pd.Grouper(key='date', freq='30d', convention='start')).size()\n",
    "tweet_df_pr = tweet_df2.groupby(pd.Grouper(key='date', freq='30d', convention='start')).size()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting \"Neurotic Tweets\" in crimson (a shade of red)\n",
    "ax.plot(tweet_df_pa, label='Neurotic Tweets', color='crimson')\n",
    "ax.yaxis.label.set_color('crimson')\n",
    "ax.spines[\"left\"].set_edgecolor('crimson')\n",
    "ax.tick_params(axis='y', colors='crimson')\n",
    "ax.spines['left'].set_color('crimson')\n",
    "plt.ylim(0, 10000)\n",
    "\n",
    "# Creating a twin axis for \"Neuroticism Tweets\" and plotting in steelblue\n",
    "ax_twin = ax.twinx()\n",
    "ax_twin.plot(tweet_df_pr, label='Neuroticism Tweets', color='steelblue')\n",
    "ax_twin.yaxis.label.set_color('steelblue')\n",
    "ax_twin.spines[\"right\"].set_edgecolor('steelblue')\n",
    "ax_twin.tick_params(axis='y', colors='steelblue')\n",
    "plt.ylim(0, 1500)\n",
    "\n",
    "\n",
    "# Setting the x-axis limits to span from 2015-01-13 to 2021-08-31\n",
    "plt.xlim([datetime.date(2015, 1, 13), datetime.date(2021, 8, 31)])\n",
    "\n",
    "# Configuring labels and title\n",
    "ax.set_xlabel('Time in Years')\n",
    "ax.set_ylabel('Tweets per 30 days', color='black')  # Setting the left y-axis label\n",
    "ax_twin.set_ylabel('Neuroticism Tweets Count', color='steelblue')  # Setting the right y-axis label\n",
    "ax.set_title(\"Tweet Frequency Over Time\")  # You can customize the title as needed\n",
    "\n",
    "# Adding legends\n",
    "ax_twin.legend(loc='upper right')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# Saving the figure\n",
    "plt.savefig(\"TweetFrequency_red_blue.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets and parse 'date' and 'acc_created' columns as dates\n",
    "tweet_df1 = pd.read_csv('dat_neurotic_added_columns.csv', parse_dates=['date', 'acc_created'])\n",
    "tweet_df2 = pd.read_csv('dat_neuroticism_added_columns.csv', parse_dates=['date', 'acc_created'])\n",
    "\n",
    "# Group tweets by 30-day intervals and count them\n",
    "tweet_df_pa = tweet_df1.groupby(pd.Grouper(key='date', freq='30d', convention='start')).size()\n",
    "tweet_df_pr = tweet_df2.groupby(pd.Grouper(key='date', freq='30d', convention='start')).size()\n",
    "\n",
    "# Setup figure and axes for plotting\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot Neurotic Tweets frequency on primary y-axis\n",
    "ax.plot(tweet_df_pa, label='Neurotic Tweets', color = 'C1')\n",
    "# Configure primary y-axis appearance\n",
    "ax.set_ylabel('Neurotic Tweets Counts', color = 'C1')\n",
    "ax.tick_params(axis='y', colors='C1')\n",
    "\n",
    "# Setup secondary y-axis for Neuroticism Tweets frequency\n",
    "ax_twin = ax.twinx()\n",
    "ax_twin.plot(tweet_df_pr, label='Neuroticism Tweets', color = 'C0')\n",
    "# Configure secondary y-axis appearance\n",
    "ax_twin.set_ylabel('Neuroticism Tweets Count', color= 'C0')\n",
    "ax_twin.tick_params(axis='y', colors='C0')\n",
    "\n",
    "# Set x-axis and y-axis limits\n",
    "plt.ylim(0, 15000)  # Primary y-axis limit\n",
    "plt.xlim([datetime.date(2015, 1, 13), datetime.date(2023, 3, 25)])  # x-axis limit\n",
    "\n",
    "# Set common labels and title\n",
    "ax.set_xlabel('Time in Years')\n",
    "ax.set_ylabel('Tweets per 30 days', color = 'black')\n",
    "\n",
    "# Add legends for both datasets\n",
    "ax.legend(loc = 'upper left')\n",
    "ax_twin.legend(loc = 'upper right')\n",
    "\n",
    "# Save the plot to a PDF file\n",
    "plt.savefig(\"TweetFrequency2.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OFFENSIVE LANGUAGE DETECTION IN NEUROTIC TWEETS (when condcuted as slurm)\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import time \n",
    "from ast import literal_eval\n",
    "import tweetnlp\n",
    "\n",
    "program_start = time.time()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess(text): \n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Paths to local model, tokenizer, and config\n",
    "local_model_path = '/home/s2463873/myenv/twitter-roberta-base-offensive'\n",
    "local_tokenizer_path = '/home/s2463873/myenv/twitter-roberta-base-offensive'\n",
    "local_config_path = '/home/s2463873/myenv/twitter-roberta-base-offensive'\n",
    "\n",
    "# Load model, tokenizer, and config from local files\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_tokenizer_path)\n",
    "config = AutoConfig.from_pretrained(local_config_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(local_model_path)\n",
    "\n",
    "#load dataframe from file\n",
    "df = pd.read_csv('dat_neurotic_short.csv')\n",
    "result = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    text = preprocess(row['rawContent'])\n",
    "    myid = row['id']\n",
    "    # Tokenize the text\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "\n",
    "    # Get model output\n",
    "    output = model(**encoded_input)\n",
    "    \n",
    "   # Extract logits and apply softmax\n",
    "    scores = softmax(output.logits[0].detach().numpy())\n",
    "    \n",
    "    formatted_probabilities = [round(float(score), 4) for score in scores]\n",
    "\n",
    "    # Determine label\n",
    "    label_indices = np.argsort(scores)[::-1]\n",
    "    labels = ['not offensive', 'offensive']  \n",
    "    predominant_label = labels[label_indices[0]]\n",
    "    \n",
    "    # Store results\n",
    "    result[myid] = {\n",
    "    'predominant_label' : predominant_label,\n",
    "    'not_offensive': formatted_probabilities [0], \n",
    "    'offensive' : formatted_probabilities [1]}\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "results_df = pd.DataFrame.from_dict(result, orient='index').reset_index().rename(columns={'index': 'id'})\n",
    "# Merge with original DataFrame\n",
    "merged_df = df.merge(results_df, on='id', how='left')\n",
    "# Save merged DataFrame\n",
    "merged_df.to_csv('2neurotic_offensive_analysis.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OFFENSIVE LANGUAGE DETECTION IN NEUROTICISM TWEETS (when condcuted as slurm)\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import time \n",
    "from ast import literal_eval\n",
    "import tweetnlp\n",
    "\n",
    "program_start = time.time()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess(text): \n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Paths to local model, tokenizer, and config\n",
    "local_model_path = '/home/s2463873/myenv/twitter-roberta-base-offensive'\n",
    "local_tokenizer_path = '/home/s2463873/myenv/twitter-roberta-base-offensive'\n",
    "local_config_path = '/home/s2463873/myenv/twitter-roberta-base-offensive'\n",
    "\n",
    "# Load model, tokenizer, and config from local files\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_tokenizer_path)\n",
    "config = AutoConfig.from_pretrained(local_config_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(local_model_path)\n",
    "\n",
    "#load dataframe from file\n",
    "df = pd.read_csv('dat_neuroticism_short.csv')\n",
    "result = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    text = preprocess(row['rawContent'])\n",
    "    myid = row['id']\n",
    "    # Tokenize the text\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "\n",
    "    # Get model output\n",
    "    output = model(**encoded_input)\n",
    "    \n",
    "   # Extract logits and apply softmax\n",
    "    scores = softmax(output.logits[0].detach().numpy())\n",
    "    \n",
    "    formatted_probabilities = [round(float(score), 4) for score in scores]\n",
    "\n",
    "    # Determine label\n",
    "    label_indices = np.argsort(scores)[::-1]\n",
    "    labels = ['not offensive', 'offensive']  \n",
    "    predominant_label = labels[label_indices[0]]\n",
    "    \n",
    "    # Store results\n",
    "    result[myid] = {\n",
    "    'predominant_label' : predominant_label,\n",
    "    'not_offensive': formatted_probabilities [0], \n",
    "    'offensive' : formatted_probabilities [1]}\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "results_df = pd.DataFrame.from_dict(result, orient='index').reset_index().rename(columns={'index': 'id'})\n",
    "# Merge with original DataFrame\n",
    "merged_df = df.merge(results_df, on='id', how='left')\n",
    "# Save merged DataFrame\n",
    "merged_df.to_csv('2neuroticism_offensive_analysis.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb39b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "# Mean offensiveness over time for both keywords\n",
    "\n",
    "# Load datasets and parse 'date' and 'acc_created' as datetime objects\n",
    "tweet_df_neurotic = pd.read_csv('2neurotic_offensive_analysis.csv', parse_dates=['date', 'acc_created'])\n",
    "tweet_df_neuroticism = pd.read_csv('2neuroticism_offensive_analysis.csv', parse_dates=['date', 'acc_created'])\n",
    "\n",
    "# Group and aggregate data before plotting\n",
    "# Only aggregate the 'offensive' column this time\n",
    "tweet_df_neurotic_mean = tweet_df_neurotic.groupby(pd.Grouper(key='date', freq='30d')).agg({'offensive': 'mean'})\n",
    "tweet_df_neuroticism_mean = tweet_df_neuroticism.groupby(pd.Grouper(key='date', freq='30d')).agg({'offensive': 'mean'})\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Neurotic Tweets - Only Offensive\n",
    "ax.plot(tweet_df_neurotic_mean.index, tweet_df_neurotic_mean['offensive'], label='Offensive Tweets (Neurotic)', color='red', linewidth=2)\n",
    "\n",
    "# Neuroticism Tweets - Only Offensive\n",
    "tweet_df_neuroticism_mean = tweet_df_neuroticism_mean.asfreq('30d').interpolate()\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(tweet_df_neuroticism_mean.index, tweet_df_neuroticism_mean['offensive'], label='Offensive Tweets (Neuroticism)', color='blue', linewidth=2)\n",
    "\n",
    "# Additional plot settings\n",
    "ax.set_xlabel('Time in Years')\n",
    "ax.set_ylabel('Mean Offensiveness Score')\n",
    "ax.grid(True)\n",
    "ax.set_ylim(0, 1)  \n",
    "ax2.set_ylim(0, 1) \n",
    "plt.xlim([pd.Timestamp('2015-01-13'), pd.Timestamp('2021-08-31')])\n",
    "\n",
    "# Legends\n",
    "ax.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "\n",
    "# Customize x-axis date formatting\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "plt.title(\"Mean Offensiveness over Time\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"2Mean_offensiveness_over_time.pdf\", format=\"pdf\", bbox_inches=\"tight\") \n",
    "\n",
    "\n",
    "#visualize neurotic offensiveness volume over time\n",
    "tweet_df_neurotic_of = tweet_df_neurotic.groupby(pd.Grouper(key='date', freq='30d', convention='start')).offensive.sum()\n",
    "tweet_df_neurotic_not = tweet_df_neurotic.groupby(pd.Grouper(key='date', freq='30d', convention='start')).not_offensive.sum()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Plot the offensive tweet volumes\n",
    "ax.plot(tweet_df_neurotic_of.index, tweet_df_neurotic_of, label='Neurotic Offensive', color='darkred')  # Changed to darkred\n",
    "# Set the limits for the primary y-axis (offensive tweets)\n",
    "ax.set_ylim(0, tweet_df_neurotic_of.max() + 1000)  # Adjust as needed\n",
    "ax.tick_params(axis='y', colors='darkred')  # Changes the ticks color\n",
    "ax.spines['left'].set_color('darkred')\n",
    "\n",
    "# Create twin axes for the not offensive tweet volumes\n",
    "ax_twin = ax.twinx()\n",
    "ax_twin.plot(tweet_df_neurotic_not.index, tweet_df_neurotic_not, label='Neurotic Not Offensive', color='salmon')  # Changed to salmon\n",
    "# Set the limits for the secondary y-axis (not offensive tweets)\n",
    "ax_twin.set_ylim(0, tweet_df_neurotic_not.max() + 1000)  # Adjust as needed\n",
    "ax_twin.tick_params(axis= 'y', colors= 'salmon')\n",
    "ax_twin.spines['right'].set_color('salmon')\n",
    "\n",
    "# Set x-axis limits\n",
    "ax.set_xlim([date(2015, 1, 13), date(2021, 8, 31)])\n",
    "\n",
    "# Labeling axes\n",
    "ax.set_xlabel('Time in Years')\n",
    "ax.set_ylabel('Number of Neurotic Offensive Tweets per 30 days', color='darkred')  # Adjusted color to darkred\n",
    "ax_twin.set_ylabel('Number of Neurotic Not Offensive Tweets per 30 days', color='salmon')  # Adjusted color to salmon\n",
    "\n",
    "# Adding a title\n",
    "ax.set_title(\"Neurotic Tweet Offensiveness Volume Over Time\")\n",
    "\n",
    "# Adding gridlines\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Adding legends\n",
    "ax.legend(loc='upper left')\n",
    "ax_twin.legend(loc='upper right')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"2Neurotic_offensive_volume_over_time.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "#visualize neuroticism Offensiveness volume over time\n",
    "\n",
    "tweet_df_neuroticism_of = tweet_df_neuroticism.groupby(pd.Grouper(key='date', freq='30d', convention='start')).offensive.sum()\n",
    "tweet_df_neuroticism_not = tweet_df_neuroticism.groupby(pd.Grouper(key='date', freq='30d', convention='start')).not_offensive.sum()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the offensive tweet volumes\n",
    "ax.plot(tweet_df_neuroticism_of.index, tweet_df_neuroticism_of, label='Neuroticism Offensive', color='navy', linewidth=2)\n",
    "# Set the primary y-axis limits and label for offensive tweets\n",
    "ax.set_ylim(0, tweet_df_neuroticism_of.max() + 100)  # Adjust as needed\n",
    "ax.set_ylabel('Number of Offensive Tweets', color='navy')\n",
    "ax.tick_params(axis= 'y', colors= 'navy')\n",
    "ax.spines['left'].set_color('navy')\n",
    "\n",
    "# Plot the not offensive tweet volumes on the twin axis\n",
    "ax_twin = ax.twinx()\n",
    "ax_twin.plot(tweet_df_neuroticism_not.index, tweet_df_neuroticism_not, label='Neuroticism Not Offensive', color='skyblue', linewidth=2)\n",
    "\n",
    "# Set the secondary y-axis limits and label for not offensive tweets\n",
    "ax_twin.set_ylim(0, tweet_df_neuroticism_not.max() + 100)  # Adjust as needed\n",
    "ax_twin.set_ylabel('Number of Not Offensive Tweets', color='skyblue')\n",
    "ax_twin.tick_params(axis= 'y', colors= 'skyblue')\n",
    "ax_twin.spines['right'].set_color('skyblue')\n",
    "\n",
    "# Set x-axis limits\n",
    "ax.set_xlim([date(2015, 1, 13), date(2021, 8, 31)])\n",
    "\n",
    "# Labeling axes\n",
    "ax.set_xlabel('Time in Years')\n",
    "\n",
    "# Adding a title\n",
    "ax.set_title(\"Neuroticism Tweet Offensiveness Volume Over Time\")\n",
    "\n",
    "# Adding gridlines for better readability\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Adding legends for both axes\n",
    "ax.legend(loc='upper left')\n",
    "ax_twin.legend(loc='upper right')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"Neuroticism_Offensiveness_volume_over_time.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOPIC MODELLING NEUROTIC TWEETS \n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from umap import UMAP\n",
    "\n",
    "#Load dataframe from file\n",
    "df = pd.read_csv('dat_neurotic_short.csv')\n",
    "tweets = df.rawContent.to_list()\n",
    "timestamps = df.date.to_list()\n",
    "\n",
    "#Generate embeddings\n",
    "sentence_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = sentence_model.encode(tweets, show_progress_bar=True)\n",
    "\n",
    "#Save the embeddings with a timestamp\n",
    "embeddings_filename = f\"neurotic_Npp_embeddings_all-mpnet-base-v2 {datetime.now().strftime('%Y-%m-%d %H_%M_%S')}.pkl\"\n",
    "\n",
    "with open(embeddings_filename, 'wb') as file:\n",
    "    pickle.dump(embeddings, file)\n",
    "\n",
    "#Load embeddings from the saved file\n",
    "with open(embeddings_filename, 'rb') as file:\n",
    "    embeddings = pickle.load(file)\n",
    "\n",
    "#Removing stop words after topic extraction\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "#Setting UMAP variables\n",
    "umap_model = UMAP(n_neighbors=10, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "#Defining the BERTopic parameters\n",
    "topic_model = BERTopic(verbose=True, nr_topics=\"auto\", min_topic_size=300, vectorizer_model=vectorizer_model, umap_model=umap_model)\n",
    "topics, probs = topic_model.fit_transform(tweets, embeddings)\n",
    "\n",
    "#Save the topic model\n",
    "topic_model_filename = \"TOPICS_neurotic_Npp_all-mpnet-base-v2_auto_mts=300_nneigh=10\"\n",
    "topic_model.save(topic_model_filename)\n",
    "\n",
    "#Create topics over time\n",
    "topics_over_time = topic_model.topics_over_time(tweets, timestamps, nr_bins=40)\n",
    "\n",
    "#Save the topics over time\n",
    "tot_filename = f\"TOT_neurotic_Npp_all-mpnet-base-v2_auto_mts=300_nneigh=10 {datetime.now().strftime('%Y-%m-%d %H_%M_%S')}.pkl\"\n",
    "\n",
    "with open(tot_filename, 'wb') as file:\n",
    "    pickle.dump(topics_over_time, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOPIC MODELLIG NEUROTICISM TWEETS\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from umap import UMAP\n",
    "\n",
    "#Load dataframe from file\n",
    "df = pd.read_csv('dat_neuroticism_short.csv')\n",
    "tweets = df.rawContent.to_list()\n",
    "timestamps = df.date.to_list()\n",
    "\n",
    "#Generate embeddings\n",
    "sentence_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = sentence_model.encode(tweets, show_progress_bar=True)\n",
    "\n",
    "#Save the embeddings with a timestamp\n",
    "embeddings_filename = f\"neuroticism_Npp_embeddings_all-mpnet-base-v2 {datetime.now().strftime('%Y-%m-%d %H_%M_%S')}.pkl\"\n",
    "\n",
    "with open(embeddings_filename, 'wb') as file:\n",
    "    pickle.dump(embeddings, file)\n",
    "\n",
    "#Load embeddings from the saved file\n",
    "with open(embeddings_filename, 'rb') as file:\n",
    "    embeddings = pickle.load(file)\n",
    "\n",
    "#Removing stop words after topic extraction\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "#Setting UMAP variables\n",
    "umap_model = UMAP(n_neighbors=6, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "#Defining the BERTopic parameters\n",
    "topic_model = BERTopic(verbose=True, nr_topics=\"auto\", min_topic_size=21, vectorizer_model=vectorizer_model, umap_model=umap_model)\n",
    "topics, probs = topic_model.fit_transform(tweets, embeddings)\n",
    "\n",
    "#Save the topic model\n",
    "topic_model_filename = \"TOPICS_neuroticism_Npp_all-mpnet-base-v2_auto_mts=21_nneigh=6\"\n",
    "topic_model.save(topic_model_filename)\n",
    "\n",
    "#Create topics over time\n",
    "topics_over_time = topic_model.topics_over_time(tweets, timestamps, nr_bins=40)\n",
    "\n",
    "#Save the topics over time\n",
    "tot_filename = f\"TOT_neurotic_Npp_all-mpnet-base-v2_auto_mts=21_nneigh=6 {datetime.now().strftime('%Y-%m-%d %H_%M_%S')}.pkl\"\n",
    "\n",
    "with open(tot_filename, 'wb') as file:\n",
    "    pickle.dump(topics_over_time, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a33e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Set the OpenAI API key\n",
    "client = OpenAI(\n",
    "    api_key='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'\n",
    ")\n",
    "\n",
    "# Load the pre-trained BERTopic model\n",
    "topic_model = BERTopic.load(\"TOPICS_neuroticism_Npp_all-mpnet-base-v2_auto_mts=21_nneigh=6\")\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('dat_neuroticism_short.csv')\n",
    "tweets = df.rawContent.to_list()\n",
    "\n",
    "# Get topics and their keywords\n",
    "topics = topic_model.get_topics()\n",
    "\n",
    "# Dictionary to store generated topic labels\n",
    "generated_topic_labels = {}\n",
    "\n",
    "# Iterating over each topic to generate labels\n",
    "for topic_num, keywords in topics.items():\n",
    "    if topic_num == -1:  # Skip the outlier topic\n",
    "        continue\n",
    "\n",
    "    documents = [doc for doc, topic in zip(tweets, topic_model.topics_) if topic == topic_num][:100]  # Adjust as needed\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    I have a topic that contains the following documents: \n",
    "    {documents}\n",
    "    The topic is also described by the following keywords: {keywords}\n",
    "\n",
    "    Based on the information above, extract a representative short and exclusvie topic label in the following format:\n",
    "    topic: <topic label>\n",
    "    The topic label should be as short as possible while being as descriptive as possible but no more than 4 words in length, no topics should have the same label The topic label should be as short as possible while being as descriptive as possible but no more than 4 words in length, no topics should have the same label and they should not mention the keywords Neuroticism or Neurotic..\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    topic_label = response.choices[0].message.content.strip()\n",
    "    generated_topic_labels[topic_num] = topic_label\n",
    "\n",
    "# Saving the generated topic labels\n",
    "with open(\"2nd_21_6_topic_labels_neuroticism.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for topic_num, label in generated_topic_labels.items():\n",
    "        file.write(f\"Topic {topic_num}: {label}\\n\")\n",
    "\n",
    "print(\"Topic labels saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60abf3-430a-4501-8b45-f4d12c953936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "import pickle\n",
    "\n",
    "# Load your BERTopic model\n",
    "topic_model = BERTopic.load(\"TOPICS_neuroticism_Npp_all-mpnet-base-v2_auto_mts=21_nneigh=6\")\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('dat_neuroticism_short.csv')\n",
    "timestamps = df.date.to_list()\n",
    "tweets = df.rawContent.to_list()\n",
    "\n",
    "# Define the dictionary of custom labels\n",
    "custom_labels = {\n",
    "    -1: \"Outliers\",\n",
    "    0: \"Personality Traits Analysis\",\n",
    "    1: \"Unique Man Descriptions\",\n",
    "    2: \"Cat Owner Dynamics\",\n",
    "    3: \"Spiritual Belief and Culture\",\n",
    "    4: \"Jewish Identity Traits\",\n",
    "    5: \"Fermented Foods Study\",\n",
    "    6: \"Racial Diversity Analysis\",\n",
    "    7: \"Psychedelic Mind Enhancement\",\n",
    "    8: \"Youthful Parental Influence\",\n",
    "    9: \"Emotional Music Listening Patterns\",\n",
    "    10: \"Trump's Psychopathic Behavior\",\n",
    "    11: \"Voter Targeting Analysis\",\n",
    "    12: \"Virgo Personality Traits\",\n",
    "    13: \"Woody Allen Films\",\n",
    "    14: \"Sexual bondage security perception\",\n",
    "    15: \"Obsessive Cleaning Habit\",\n",
    "    16: \"Urban Stress Culture\",\n",
    "    17: \"Masking Behavior Study\",\n",
    "    18: \"Emotional Music Analysis\",\n",
    "    19: \"MBTI Validity Critique\",\n",
    "    20: \"Caffeine Addiction Trends\",\n",
    "    21: \"Perfectionism and early death\",\n",
    "    22: \"Sleep Patterns & Habits\",\n",
    "    23: \"Erotic Societal Studies\",\n",
    "    24: \"Trumpian Attributes\",\n",
    "    25: \"TV Shows Analysis\",\n",
    "    26: \"Google Engineer Controversy Manifesto\",\n",
    "    27: \"Cat Parasite Harmful Effects\",\n",
    "    28: \"Web Forum Viral Trend\",\n",
    "    29: \"Scott's Unique Loyalty\",\n",
    "    30: \"Genetic Cannabis Addiction Risk\",\n",
    "    31: \"Fearful Voting Patterns\",\n",
    "    32: \"Writing Prison Release Joyful\",\n",
    "    33: \"EU Dangers Misinfo Exit\",\n",
    "    34: \"Fear of Falling\",\n",
    "    35: \"Fan Anxiety Analysis\",\n",
    "    36: \"Character Contrasts & Traits\",\n",
    "    37: \"Industrial Progress Struggles\",\n",
    "    38: \"Eye Movement Personality Prediction\",\n",
    "    39: \"Writing Prison Bars Release\",\n",
    "    40: \"College Drinking Link\",\n",
    "    41: \"Humorous Personality Traits\",\n",
    "    42: \"Denial Reality Distortions\",\n",
    "    43: \"Quirky Behavior Appreciation\",\n",
    "    44: \"Newton's Overthinking Syndrome\",\n",
    "    45: \"Emotional Face Study\",\n",
    "    46: \"Intense Emotional Behavior\",\n",
    "    47: \"Trump Personality Traits\",\n",
    "    48: \"Brexit Influence Tactics\",\n",
    "    49: \"Early Birth Aversion\",\n",
    "    50: \"Targeted Ad Marketing\",\n",
    "    51: \"Vegan Food Debate\",\n",
    "    52: \"Vaccine Preferences\",\n",
    "    53: \"Woke Hypocrisy & Ideology\",\n",
    "    54: \"Med Student Concerns\",\n",
    "    55: \"Gun Owner Behavior Study\",\n",
    "    56: \"Phone Ignoring Behavior\",\n",
    "    57: \"Character Portrayals\",\n",
    "    58: \"Personality Trait Change\",\n",
    "    59: \"Emotional Turmoil in Relationships\",\n",
    "    60: \"Media Influence on Journalism\",\n",
    "    61: \"Testosterone Influence Cerebellum Link\",\n",
    "    62: \"ADHD Genetic Links\",\n",
    "    63: \"Self-compassion overlap discovery\",\n",
    "    64: \"Social Media Cult Behavior\",\n",
    "    65: \"Festive Winter Holidays\",\n",
    "    66: \"Celebrity Influence Analysis\",\n",
    "    67: \"Bondage Security Relationship Practice\",\n",
    "    68: \"College AI Grading Technology\",\n",
    "    69: \"Smokers Personality Changes\",\n",
    "    70: \"Mountainous Personality Traits\",\n",
    "    71: \"Synthpunk Album Review\"\n",
    "}\n",
    "\n",
    "\n",
    "# Set the custom labels\n",
    "topic_model.topic_labels_ = custom_labels  # Directly setting the attribute to ensure it's applied\n",
    "\n",
    "# Save the model again with the custom labels\n",
    "topic_model.save(\"TOPICS_neuroticism_Npp_all-mpnet-base-v2_auto_mts_21_nneigh_6_CUSTOM_LABELS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4ccfe-c10d-4f0e-bb3f-5c8fcff001e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Load the model\n",
    "topic_model = BERTopic.load(\"TOPICS_neuroticism_Npp_all-mpnet-base-v2_auto_mts_21_nneigh_6_CUSTOM_LABELS\")\n",
    "\n",
    "#create tot\n",
    "topics_over_time = topic_model.topics_over_time(tweets, timestamps, nr_bins=40)\n",
    "    \n",
    "#pickle the topics over time\n",
    "filename = f\"TOT_neuroticism_Npp_all-mpnet-base-v2_auto_mts=21_nneigh=6-CUSTOM_LABELS.pkl\"\n",
    "filename = filename.replace(\":\", \"_\")\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(topics_over_time, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b6683-7faf-4134-a396-0dec28ee5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Load the model\n",
    "topic_model = BERTopic.load(\"TOPICS_neuroticism_Npp_all-mpnet-base-v2_auto_mts_21_nneigh_6_CUSTOM_LABELS\")\n",
    "\n",
    "# Retrieve topic information\n",
    "topic_info = topic_model.get_topic_info()\n",
    "\n",
    "# Map custom labels\n",
    "topic_info['Label'] = topic_info['Topic'].apply(lambda x: topic_model.topic_labels_.get(x, \"No Label\"))\n",
    "\n",
    "# Calculate the percentage of the total for each topic\n",
    "total_documents = topic_info['Count'].sum()\n",
    "topic_info['Percentage'] = (topic_info['Count'] / total_documents) * 100\n",
    "\n",
    "# Map keywords and representative documents\n",
    "topic_keywords = {topic: ', '.join([word for word, _ in topic_model.get_topic(topic)]) for topic in topic_model.get_topics()}\n",
    "topic_info['Keywords'] = topic_info['Topic'].map(topic_keywords)\n",
    "representative_docs = topic_model.get_representative_docs()\n",
    "topic_info['Representative Tweet'] = topic_info['Topic'].map(representative_docs)\n",
    "\n",
    "# Remove outliers if necessary\n",
    "#if -1 in topic_info['Topic'].values:\n",
    " #   topic_info = topic_info[topic_info['Topic'] != -1]\n",
    "\n",
    "# Select relevant columns to save\n",
    "columns_to_save = ['Topic', 'Label', 'Count', 'Percentage', 'Keywords', 'Representative Tweet']\n",
    "final_dataframe = topic_info[columns_to_save]\n",
    "\n",
    "# Save to CSV\n",
    "final_dataframe.to_csv('21_6_neuroticism_topic_details.csv', index=False)\n",
    "\n",
    "print('topic infos saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f1d35-98e6-40ad-9529-49fdfda51e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all neuroticism figures to PDF and HTML\n",
    "import plotly.io as pio   \n",
    "pio.kaleido.scope.mathjax = None\n",
    "\n",
    "topic_model = BERTopic.load(\"TOPICS_neuroticism_Npp_all-mpnet-base-v2_auto_mts_21_nneigh_6_CUSTOM_LABELS\")\n",
    "df = pd.read_csv('dat_neuroticism_short.csv')\n",
    "timestamps = df.date.to_list()\n",
    "tweets = df.rawContent.to_list()\n",
    "\n",
    "with open('neuroticism_Npp_embeddings_all-mpnet-base-v2 2024-04-16 17_06_15.pkl', 'rb') as file:\n",
    "    embeddings = pickle.load(file)\n",
    "\n",
    "\n",
    "fig1 = topic_model.visualize_topics(custom_labels=True)\n",
    "pio.write_html(fig1, file='21_6_intertopic-neuroticism-custom_labels.html', auto_open=False)\n",
    "#pio.write_image(fig1, file='topics-neuroticism-custom_labels.pdf', format='pdf')\n",
    "\n",
    "topics_over_time = topic_model.topics_over_time(tweets, timestamps, nr_bins=40)\n",
    "fig2 = topic_model.visualize_topics_over_time(topics_over_time, custom_labels=True)\n",
    "pio.write_html(fig2, file='21_6_tot-neuroticism-custom_labels.html', auto_open=False)\n",
    "#pio.write_image(fig2, file='tot-neuroticism-custom_labels.pdf', format='pdf')\n",
    "\n",
    "fig3 = topic_model.visualize_term_rank(custom_labels=True)\n",
    "pio.write_html(fig3, file='21_6_term_rank-neuroticism-custom_labels.html', auto_open=False)\n",
    "#pio.write_image(fig3, file='term_rank-neuroticism-custom_labels.pdf', format='pdf')\n",
    "\n",
    "fig4 = topic_model.visualize_barchart(top_n_topics=12, custom_labels=True)\n",
    "pio.write_html(fig4, file='21_6_barchart-neuroticism-custom_labels.html', auto_open=False)\n",
    "#pio.write_image(fig4, file='barchart-neuroticism-custom_labels.pdf', format='pdf')\n",
    "\n",
    "hierarchical_topics = topic_model.hierarchical_topics(tweets)\n",
    "fig5 = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics, custom_labels=True)\n",
    "pio.write_html(fig5, file='21_6_hierarchy-neuroticism-custom_labels.html', auto_open=False)\n",
    "#pio.write_image(fig5, file='hierarchy-neuroticism-custom_labels.pdf', format='pdf')\n",
    "\n",
    "fig6 = topic_model.visualize_hierarchy(custom_labels=True)\n",
    "pio.write_html(fig6, file='21_6_simple_hierarchy-neuroticism-custom_labels.html', auto_open=False)\n",
    "#pio.write_image(fig6, file='simple_hierarchy-neuroticism-custom_labels.pdf', format='pdf')\n",
    "\n",
    "fig7 = topic_model.visualize_heatmap(custom_labels=True)\n",
    "pio.write_html(fig7, file='21_6_heatmap-neuroticism-custom_labels.html', auto_open=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
